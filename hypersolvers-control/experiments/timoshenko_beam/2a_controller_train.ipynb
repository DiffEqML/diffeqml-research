{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544a732b-07bc-4b4d-833d-3a868e13ce70",
   "metadata": {},
   "source": [
    "# Timoshenko Beam Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaptive-ontario",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchdyn.datasets import *\n",
    "from torchdyn.numerics import odeint, Euler, HyperEuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57693fc-db8e-495d-b293-3bc1299e71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.append(2*'../') # go n dirs back\n",
    "from src import *\n",
    "from dicts import *\n",
    "from timoshenko_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90232c0f-f410-4ccc-ac1b-fa5ba9856e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change device according to your configuration\n",
    "# device = torch.bdevice('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea3ef8-94f0-4b1b-9f36-09f8f3d08713",
   "metadata": {},
   "source": [
    "### Load Timoshenko Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c787b39-edb5-406d-a0e1-e686b1f1296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load discretization data\n",
    "A = torch.load('A_sys').to(device).float()\n",
    "B = torch.load('B_sys').to(device).float()\n",
    "x0 = torch.load('x0')[None].to(device).float()\n",
    "x_dim, u_dim = x0.shape[1], 2\n",
    "\n",
    "u = BoxConstrainedController(x_dim, u_dim, h_dim=512, num_layers=3).to(device)\n",
    "\n",
    "f = TimoshenkoBeam(A, B, u).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310d562-013f-41f1-9f06-43550be22bd0",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ec2b9f-e25c-4ab2-8883-8a312a583396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperNet(nn.Module):\n",
    "    \"\"\"Simple hypernetwork for controlled systems\n",
    "    Input: current x, f and u from the controlled system\n",
    "    Output: p-th order residuals\"\"\"\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        xfu = torch.cat([x, f.cur_f, f.cur_u], -1)\n",
    "        return self.net(xfu)\n",
    "# hdim = 256\n",
    "# snake_activation = Snake(hdim)\n",
    "hypersolver = torch.load('saved_models/hypersolver_0.005_256_snake_rw_layers_2_new.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf23be13-0db2-4a9a-902b-693eae1d5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_low = torch.Tensor([-1, -1]).to(device)\n",
    "u_high = torch.Tensor([1, 1]).to(device)\n",
    "u_dist = torch.distributions.Uniform(u_low, u_high)\n",
    "f.u = RandConstController()\n",
    "\n",
    "f.u.u0 = u_dist.sample((1,)) # set  random controller to be common for all experiments\n",
    "t0, tf, dt = 0, 3, 0.005\n",
    "steps = int((tf - t0)/dt) + 1\n",
    "t = torch.linspace(t0, tf, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-heart",
   "metadata": {},
   "source": [
    "### Train with `odeint` and `Pytorch Lightning`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spare-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from numpy import pi\n",
    "import time\n",
    "\n",
    "def dummy_trainloader():\n",
    "    tl = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.Tensor(1), torch.Tensor(1)), batch_size=1)\n",
    "    return tl\n",
    "\n",
    "trainloader = dummy_trainloader()\n",
    "x0 = torch.load('x0')[None].to(device).float()\n",
    "x_dim, u_dim = x0.shape[1], 2\n",
    "\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 model:nn.Module,\n",
    "                 span,\n",
    "                 solver='rk4',\n",
    "                 lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = model.to(device)\n",
    "        self.t = span.to(device)\n",
    "        self.solver = solver\n",
    "        self.lr=lr\n",
    "        self.z0 = x0\n",
    "        self.model.nfe = 0 \n",
    "        self.flag = 0\n",
    "        self.current_time = 0\n",
    "        self.times = []\n",
    "        \n",
    "    def forward(self):\n",
    "        _, zT = odeint(self.model, self.z0, self.t, \n",
    "                    solver=self.solver)\n",
    "        return zT\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):      \n",
    "        if not self.flag:\n",
    "            self.current_time = time.time()\n",
    "            self.flag = 1.        \n",
    "        fw_time = time.time() - self.current_time\n",
    "        self.current_time = time.time()\n",
    "        \n",
    "        # save times for each forward pass\n",
    "        if self.flag:\n",
    "            self.times.append(fw_time)\n",
    "        \n",
    "        # forward pass\n",
    "        self.model.nfe = 0\n",
    "\n",
    "        zT = self()\n",
    "        fw_nfe = self.model.nfe\n",
    "\n",
    "        control_loss = torch.norm(zT[:,0,dofs_dict['sig_t']], p=2, dim=-1).mean()\n",
    "        control_loss = control_loss + torch.norm(zT[:,0,dofs_dict['sig_r']], p=2, dim=-1).mean()\n",
    "        reg_loss = 1e-3*self.model.u(0., zT).abs().mean()\n",
    "        loss = control_loss + reg_loss\n",
    "        return {'loss': loss}   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.u.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cecff1-d63a-40b9-b027-55aa3bef0b13",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2c2954-c69a-4d57-896a-28fe4a357677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time span\n",
    "t0, dt, tf = 0, 0.005, 3\n",
    "steps = int((tf - t0)/dt) + 1\n",
    "t = torch.linspace(t0, tf, steps)\n",
    "\n",
    "# Training hyperparameters\n",
    "lr = 1e-3\n",
    "epochs = 1000\n",
    "h_dim = 1024\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ecae2-92a9-40c2-8e79-268d183a5bbf",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0f8d6-e2c2-41cf-9fa7-0fd348145b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/botu/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/botu/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name   | Type           | Params\n",
      "------------------------------------------\n",
      "0 | model  | TimoshenkoBeam | 2 M   \n",
      "1 | solver | HyperEuler     | 189 K \n",
      "/home/botu/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb9c9521470471c9f56ce6b2316de52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solver\n",
    "solver = hypersolver\n",
    "\n",
    "# Controller\n",
    "u = BoxConstrainedController(x_dim, u_dim, h_dim=h_dim, num_layers=num_layers, constrained=True).to(device)\n",
    "f.u = u\n",
    "\n",
    "# Train\n",
    "learn = Learner(f, t, solver=solver, lr=lr).to(device)\n",
    "trainer = pl.Trainer(max_epochs=epochs, gradient_clip_val=.3) #, logger=logger\n",
    "trainer.fit(learn)\n",
    "\n",
    "# Save\n",
    "torch.save(f.u, 'saved_models/u_hypersolver.pt')\n",
    "training_times = learn.times[1:] # exclude the first dummy time\n",
    "\n",
    "exp = 'hypersolver'\n",
    "with open(\"results/\"+exp+\"_times.txt\", \"w\") as output:\n",
    "    output.write(str(training_times))\n",
    "    \n",
    "print(r'Mean runtime : {} ± {} s'.format(round(np.mean(training_times), 4), round(np.std(training_times), 4)))\n",
    "print(r'Total runtime : {} s'.format(round(np.sum(training_times), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed574203-1620-4191-89a8-505f68714d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "solver = 'rk4'\n",
    "\n",
    "# Controller\n",
    "u = BoxConstrainedController(x_dim, u_dim, h_dim=h_dim, num_layers=num_layers, constrained=True).to(device)\n",
    "f.u = u\n",
    "\n",
    "# Train\n",
    "learn = Learner(f, t, solver=solver, lr=lr).to(device)\n",
    "trainer = pl.Trainer(max_epochs=epochs, gradient_clip_val=.3) #, logger=logger\n",
    "trainer.fit(learn)\n",
    "\n",
    "# Save\n",
    "torch.save(f.u, 'saved_models/u_rk4.pt')\n",
    "training_times = learn.times[1:] # exclude the first dummy time\n",
    "\n",
    "exp = 'rk4'\n",
    "with open(\"results/\"+exp+\"_times.txt\", \"w\") as output:\n",
    "    output.write(str(training_times))\n",
    "    \n",
    "print(r'Mean runtime : {} ± {} s'.format(round(np.mean(training_times), 4), round(np.std(training_times), 4)))\n",
    "print(r'Total runtime : {} s'.format(round(np.sum(training_times), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab9883-e1e6-4704-822c-b1f23759afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "solver = 'midpoint'\n",
    "\n",
    "# Controller\n",
    "u = BoxConstrainedController(x_dim, u_dim, h_dim=h_dim, num_layers=num_layers, constrained=True).to(device)\n",
    "f.u = u\n",
    "\n",
    "# Train\n",
    "learn = Learner(f, t, solver=solver, lr=lr).to(device)\n",
    "trainer = pl.Trainer(max_epochs=epochs, gradient_clip_val=.3) #, logger=logger\n",
    "trainer.fit(learn)\n",
    "\n",
    "# Save\n",
    "torch.save(f.u, 'saved_models/u_midpoint.pt')\n",
    "training_times = learn.times[1:] # exclude the first dummy time\n",
    "\n",
    "exp = 'midpoint'\n",
    "with open(\"results/\"+exp+\"_times.txt\", \"w\") as output:\n",
    "    output.write(str(training_times))\n",
    "    \n",
    "print(r'Mean runtime : {} ± {} s'.format(round(np.mean(training_times), 4), round(np.std(training_times), 4)))\n",
    "print(r'Total runtime : {} s'.format(round(np.sum(training_times), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f97e7-73d6-4cd4-92f0-7014d22397f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver\n",
    "solver = 'euler'\n",
    "\n",
    "# Controller\n",
    "u = BoxConstrainedController(x_dim, u_dim, h_dim=h_dim, num_layers=num_layers, constrained=True).to(device)\n",
    "f.u = u\n",
    "\n",
    "# Train\n",
    "learn = Learner(f, t, solver=solver, lr=lr).to(device)\n",
    "trainer = pl.Trainer(max_epochs=epochs, gradient_clip_val=.3) #, logger=logger\n",
    "trainer.fit(learn)\n",
    "\n",
    "# Save\n",
    "torch.save(f.u, 'saved_models/u_euler.pt')\n",
    "training_times = learn.times[1:] # exclude the first dummy time\n",
    "\n",
    "exp = 'euler'\n",
    "with open(\"results/\"+exp+\"_times.txt\", \"w\") as output:\n",
    "    output.write(str(training_times))\n",
    "    \n",
    "print(r'Mean runtime : {} ± {} s'.format(round(np.mean(training_times), 4), round(np.std(training_times), 4)))\n",
    "print(r'Total runtime : {} s'.format(round(np.sum(training_times), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef42f1-95b4-4a98-8648-86ef7b6687c3",
   "metadata": {},
   "source": [
    "### Test controller with nominal trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4fee2-119c-419a-8ff8-1a449e888466",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 5, 500+1)\n",
    "\n",
    "def plot_test_controller(f, x0, \n",
    "                         span=torch.linspace(0, 5, 500+1), \n",
    "                         title='Euler trajectories and control policy'):\n",
    "    _, xT = odeint(f.to(device), x0.to(device), t, solver='tsit5', atol=1e-5, rtol=1e-5)\n",
    "    xT = xT.detach().cpu()\n",
    "    uT = f.u(0, xT.to(device))\n",
    "\n",
    "    v_t = xT[:,0,dofs_dict['v_t']]\n",
    "    v_r = xT[:,0,dofs_dict['v_r']]\n",
    "    sig_t = xT[:,0,dofs_dict['sig_t']]\n",
    "    sig_r = xT[:,0,dofs_dict['sig_r']]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 5))\n",
    "    axs[0].plot(t.cpu(), v_t, ':k');\n",
    "    axs[0].plot(t.cpu(), v_r, 'b');\n",
    "    axs[1].plot(t.cpu(), sig_t, ':k');\n",
    "    axs[1].plot(t.cpu(), sig_r, 'b');\n",
    "    axs[2].plot(t.cpu(), uT[:,0,:].detach().cpu(), ':b');\n",
    "\n",
    "plot_test_controller(f, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84822b-f059-4f17-b18b-56d6ba2553ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_t = xT[:,0,dofs_dict['v_t']].cpu()\n",
    "v_r = xT[:,0,dofs_dict['v_r']].cpu()\n",
    "sig_t = xT[:,0,dofs_dict['sig_t']].cpu()\n",
    "sig_r = xT[:,0,dofs_dict['sig_r']].cpu()\n",
    "\n",
    "x_v_t = x_dict['v_t'].cpu()\n",
    "x_v_r = x_dict['v_r'].cpu()\n",
    "x_sig_t = x_dict['sig_t'].cpu()\n",
    "x_sig_r = x_dict['sig_r'].cpu()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0,0].scatter(x_v_t, v_t[-1])\n",
    "axs[0,1].scatter(x_v_r, v_r[-1])\n",
    "axs[1,0].scatter(x_sig_t, sig_t[-1])\n",
    "axs[1,1].scatter(x_sig_r, sig_r[-1])\n",
    "axs[0,0].scatter(x_v_t, v_t[0])\n",
    "axs[0,1].scatter(x_v_r, v_r[0])\n",
    "axs[1,0].scatter(x_sig_t, sig_t[0])\n",
    "axs[1,1].scatter(x_sig_r, sig_r[0])\n",
    "\n",
    "axs[1,0].set_ylim([-.1, .1])\n",
    "axs[1,1].set_ylim([-.1, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca81173-61b0-4b2c-81bd-d2212c5bee52",
   "metadata": {},
   "source": [
    "## Complexity and FLOPS calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cddd5-1427-4abb-b4f7-bfe76d8580e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "bs = 1 # batch size we used in training\n",
    "def get_macs(net:nn.Module):\n",
    "    params = []\n",
    "    for p in net.parameters(): params.append(p.shape)\n",
    "    with torch.cuda.device(0):\n",
    "        macs, _ = get_model_complexity_info(net, (bs, params[0][1]), as_strings=False)\n",
    "    return int(macs)\n",
    "\n",
    "controller_test = nn.Sequential(\n",
    "                nn.Linear(160, 1024),\n",
    "                nn.Softplus(),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.Softplus(),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1024, 2))\n",
    "\n",
    "hypersolver_test = nn.Sequential(nn.Linear(322, 256), nn.Softplus(), nn.Linear(256, 256), \n",
    "                                 nn.Softplus(), nn.Linear(256, 160)).to(device)\n",
    "\n",
    "hs_macs = get_macs(hypersolver_test)\n",
    "u_macs = get_macs(controller_test)\n",
    "\n",
    "print('Controller MACs per NFE:', u_macs, '\\nHypersolver MACs per NFE:', hs_macs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
